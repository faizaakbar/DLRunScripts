[RunOpts]
num_epochs: <int>       # number of complete passes over the training files to run
log_level: <string>     # DEBUG, INFO, etc. - control log output (uses Python logger)
a_short_run: <int 0/1>  # if ==1, only run over 20 events - useful for quick check debugging
log_devices: <int 0/1>  # if ==1, write a bunch of extra log info about the cpu/gpu used
training: <int 0/1>     # if ==1, run the training step
validation: <int 0/1>   # if ==1, run validation after each training epoch
testing: <int 0/1>      # if ==1, run the test phase
prediction: <int 0/1>   # if ==1, run prediction (does not require ground truth for accuracy, etc.)
use_all_for_test: <int 0/1>   # if ==1, use all the files for testing/prediction
use_test_for_train: <int 0/1> # if ==1, include files marked 'test' in the training phase
use_valid_for_test: <int 0/1> # if ==1, include files marked 'valid' in the testing/pred. phase
job_base_dir: <string>  # where should the job code be copied to
pred_store_use_db: <int 0/1>  # if ==1, write predictions to SQLite, otherwise to txt (requires
                              # SQLAlchemy Python package to write to SQLite)

# *Note*: the `use_all_for_test`, `use_test_for_train`, and `use_valid_for_test` flags can be
# confusing. Simulation files are split when TFRecords are produced into `_train`, `_valid`,
# and `_test` files. Data files are only written to `_test`. This split is useful when doing
# everything with 1 MC playlist, but when working with many, it can be wasteful to set aside
# files for testing. For example, we train with playlists LOP to make predictions for MN. In
# this case, it makes sense during training to set `use_test_for_train` as 1 - the real "test"
# involves a different playlist. In this case we also set `use_valid_for_test` to 1 and use
# the validation sample for "testing" if we want to look at a confusion matrix, etc. When
# making predictions for a MC playlist, we need to set `use_all_for_test` to 1 in order to make
# a prediction for every event and not just those marked `_test`. Statistical independence
# at training comes from the fact we will have trained on a different MC playlist than the
# one used to make predictions.

[DataDescription]
n_classes: <int>        # number of classes predicted for classification
n_planecodes: <int>     # number of plane codes 
imgw_x: <int>           # image width for the x-view, usually 94 (no H-cal)
imgw_uv: <int>          # image width for the u and v-views, usually 47
targets_label: <string> # variable in the TFRecord used as a target for classification
tfrec_type: <string>    # what "kind" of TFRecord are we unpacking - they are coded by string
filepat: <string>_127x  # usually use the same value as for `tfrec_type` - the script assumes it
                        # will need to append `imgw_x` after `_127x` to make a search pattern for
                        # filling the internal files list.
compression: gz         # TFRecords *must* be compressed or they will be too large to store and use.
                        # Can also handle zlib compressed files (.zz).

# *Note*: `tfrec_type` cannot be arbitrary. Generally, use `hadmultkineimgs` for simulation and
# `mnvimgs` for data.

# these control the labels in the model code only, not data selection
# `pred` controls the predictions file label, but not the model code.
[SampleLabels]
train: <string>       # usually <beam><playlists><mc/dat>, e.g., me1Amc, or me1ABDGmc
valid: <string>       # usually the same as `train`
test: <string>        # usually the same as `valid` and `train`
override_machine_name_in_model: <int 0/1>  # if ==1, use specified machine name in model file
machine_name_in_model: <string>  # machine name overwrite - useful when training on one machine
                                 # and testing/predicting on another
pred: <string>        # usually <beam><playlists><mc/dat>, e.g., me1Amc for the name of the 
                      # predictions file

# many of the 'Training' block labels go into the 'model code' (string used to specifiy the
# model directory TensorFlow uses to store weights).
[Training]
network_creator: default  # leave as "default" unless you really know what you are doing - 
                          # controls which network architecture template is used
optimizer: Adam           # leave as "Adam" unless you really know what you are doing - 
                          # controls which SGD algorithm is used for optimization
batch_norm: 0             # leave as 0 unless you really know what you are doing - 
                          # activates batch normalizaiton if ==1
batch_size: 1024          # leave as 1024 unless you really know what you are doing - 
                          # controls batch size during training
save_every_n_batch: <int> # how frequently (in batches) to save the model weights during
                          # training

# if `log_path` is empty, use job directory;
# `processing_version` will be appended to `data_`, `models_`, and `pred_` paths;
# `data_ext_dirs` should be a comma separated list that will be appended, one at
# time to the `data_path` to build a list of `data_path`s;
[Paths]
processing_version: <int>  # processing code
model_version: 20180403_def_chngdpad  # model code base prefix, use `20180403_def_chngdpad`
                                      # for vertex finding unless you know what you are doing
data_path: <path>                     # base path to the files, data is handled a bit different
                                      # than mc for the vertex finding problem (see below)
data_ext_dirs: playlist1,playlist2    # list of extensions to add to the `data_path` - for stitching
                                      # together file lists into one master internal list with multiple
                                      # playlists
log_path:               # generally leave this blank
models_path: <path>     # path to location models are stored              
pred_path: <path>       # path to where we want to write predictions

# *Note*: processing codes: 201801 should be used for data, 201804 for water-target
# enabled MC (for vertex finding). Data is special here - we actually want to put
# 201804 and then append 201801 to the end of the `data_path` - this is because we are
# storing the data in a different place in the directory structure than the MC - we
# had to reprocess the MC (changing the `processing_version` from 201801 to 201804)
# to handle the water target, but we wanted to avoid reprocessing the data. So we have a
# "hack" that uses 201804 for the `processing_version` for the purposes of building up
# the 'model code', but if we add a processing version to the end of the `data_path`,
# then the raw `data_path` is used w/o appending the processing version (which is the
# usual convention). 

[Singularity]
container: /data/perdue/singularity/tf_1_4.simg  # leave alone unless you know what to do

[Code]
code_source_dir: </path/to/ANNMINERvA>  # locaiton of ANNMINERvA code
restore_repo: <0/hash>   # if a git hash, checkout that version of the ANNMINERvA code
                         # before starting a job  
run_script: mnv_run_categorical.py  # use `mnv_run_categorical.py` unless you know what
                                    # you are doing, etc.
